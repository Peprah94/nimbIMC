family,
x,
y,
target,
control = samplerControl)
#compile Model
compileModel <- compileNimble(mwtc, rr)
model = mwtc
#control list extraction
nimbleINLA <- extractControlElement(control, 'nimbleINLA',  NULL)
fixedVals <- extractControlElement(control, 'fixedVals',  double())
proposal <- extractControlElement(control, 'proposal',  character())
initMean <- extractControlElement(control, 'initMean',  NULL)
initCov <- extractControlElement(control, 'initCov',  NULL)
initEcoPars <- extractControlElement(control, 'initEcoPars',  NULL)
initModel <- extractControlElement(control, 'initModel',  FALSE)
timeIndex <- extractControlElement(control, 'timeIndex',  double()) #Nt
nSteps <- extractControlElement(control, 'nSteps',  integer()) #Number of steps at each direction
nCores <- extractControlElement(control, 'nCores',  NULL)
dfTdist <- extractControlElement(control, 'dfTdist',  NULL)
adaptive <- extractControlElement(control, 'adaptive',  TRUE)
additionalPars <- extractControlElement(control, 'additionalPars',  NULL)
latentIsDependent <- extractControlElement(control, 'latentIsDependent',  FALSE)
betaWts <- extractControlElement(control, 'betaWts',  NULL)
latentWts <- extractControlElement(control, 'latentWts',  NULL)
#latentIsDependent must be logical
if(!is.logical(latentIsDependent)) stop("latentIsDependent must be either TRUE or FALSE, indicating whether the latent variable is dependent on the other MCMC parameters.")
if(!is.logical(adaptive)) stop("adaptive must be logical: either TRUE or FALSE, indicating whether the parameters of the proposal distribution are adapted or not.")
#Note
# In the original paper:
## timeIndex = Nt
## nSteps = t
isDic <- sapply(target, function(x){
all(model$isDiscrete(nodes = x))==TRUE
})
nTarget <- length(target)
dataVar <- y
if(!is.character(y)) stop("'y' must be the node nae for the data variable")
y <- model[[y]]
if(nTarget < 2) stop("Function only works for more than two target variables")
# if there are discrete variables, seperate them from the continuous ones
discreteTarget <- target[isDic]
contTarget <- model$expandNodeNames(nodes = target[!isDic], returnScalarComponents = TRUE)
# I need to check the dependency of these discrete and continuous variables
# and see which one is ecological (latent) and observation parameters
#if(all(model$getDependencies(contTarget, stochOnly = TRUE, includeData = FALSE) %in% contTarget)){
obsParams <- contTarget
ecoParams <- discreteTarget
if(is.null(nCores)) nCores <- 1
if(is.null(dfTdist)) dfTdist <- 1
if(!proposal %in% c("normal", "studentT", "prior")) stop("Proposal distribution must be either 'normal', 'student T' and 'prior' distributions.")
if(proposal == "prior") adaptive <- FALSE
#yExpand <- model$expandNodeNames(y, returnScalarComponents = TRUE)
#y <- model[[y]]
#y <- c(nimble::values(model, yExpand))
my_initializeModel <- initializeModel(model, silent = TRUE)
#save posterior samples
#modelVals = modelValues(model, m = 1)
if(is.null(additionalPars)){
vars <- model$getVarNames(nodes = c(fixedVals, target))
}else{
vars <- model$getVarNames(nodes = c(fixedVals, target, additionalPars))
}
modelSymbolObjects <- model$getSymbolTable()$getSymbolObjects()[vars]
names <- sapply(modelSymbolObjects, function(x)return(x$name))
type <- sapply(modelSymbolObjects, function(x)return(x$type))
size <- lapply(modelSymbolObjects, function(x)return(x$size))
size <- lapply(size, function(x){
if(length(x) == 0){
#length(model$vars)
ret <- 1 #c(1, timeIndex)
# return(ret)
}else{
ret <- x #c(x, timeIndex)
}
return(ret)
} )
#size$beta <- 4
if("gamma" %in% names) stop("change the variable name of gamma.")
# Add names and dimensions for wts and gamma
names <- c(names,
"wts", "wtsObsParams",
"gamma", "gammaObsParams",
"logLike", "logLikeObsParams",
"wtsLatent",
"betaWeights", "latentWeights", "obsParamsWeights")
type <- c(type, rep("double", 10))
size$wts <- nSteps
size$wtsObsParams <- nSteps
size$wtsLatent <- nSteps
size$gamma <- nSteps
size$gammaObsParams <- nSteps
#size$gamma2 <- nSteps
size$logLike <- nSteps
size$logLikeObsParams <- nSteps
size$betaWeights <- 1
size$latentWeights <- 1
size$obsParamsWeights <- 1
#size$logLike2 <- nSteps
#print(1)
#model values to save results
mvEWSamples <- modelValues(modelValuesConf(vars = names,
types = type,
sizes = size))
mvWSamples <- modelValues(modelValuesConf(vars = names,
types = type,
sizes = size))
fixedVals <- model$expandNodeNames(fixedVals)
# Set initial mean and covariance
nContVars <- length(contTarget)
initMean <- rep(0, nContVars)
initCov <- diag(nContVars)
#   #create matrix to store updated mean and covariance matrix
muStep <- matrix(0, nrow = nSteps+1, ncol = nContVars)
sigmaStep <- array(0, dim = c(nContVars, nContVars, nSteps+1))
meanEcoParsStep <- rep(0, nSteps + 1)
#   # initialize the storage matrix
muStep[1,] <- initMean
sigmaStep[,,1] <- initCov
meanEcoParsStep[1] <- initEcoPars
initEcoPars
if(is.null(initEcoPars)) initEcoPars <- 0.5
meanEcoParsStep[1] <- initEcoPars
# Print all the parameters for users:
print(paste("Multiple parameters used sampled with Importance Sampling:", is.null(discreteTarget)))
print(paste("Ecological process parameters sampled using Importance Sampling:", discreteTarget))
print(paste("Observation process parameters sampled using Importance Sampling:", contTarget))
#message(paste0("Latent state sampled using Importance Sampling:", discreteTarget))
print(paste("Other parameters sampled from INLA:", fixedVals))
impSampINLAstepFnx <- nimbleFunctionList(importanceSamplingStepVirtualMultiple)
#for(iNode in seq_along(nodes)){
# beta <- target
for(iNode in 1:nSteps){
impSampINLAstepFnx[[iNode]] <- impSampINLAstepMultiple(model,
mvEWSamples,
mvWSamples,
fixedVals,
iNode,
x, #covariates
y, #response variable
# interInModel,
fam,
proposal, #proposal distribution
obsParams, # continuous variables which we specify normal or T-distribution for
ecoParams,
discreteTarget, # Discrete random variables
timeIndex,
vars,
nCores,
dfTdist,
adaptive,
additionalPars,
dataVar,
latentIsDependent
)
}
fam = "binomial"
#for(iNode in seq_along(nodes)){
# beta <- target
for(iNode in 1:nSteps){
impSampINLAstepFnx[[iNode]] <- impSampINLAstepMultiple(model,
mvEWSamples,
mvWSamples,
fixedVals,
iNode,
x, #covariates
y, #response variable
# interInModel,
fam,
proposal, #proposal distribution
obsParams, # continuous variables which we specify normal or T-distribution for
ecoParams,
discreteTarget, # Discrete random variables
timeIndex,
vars,
nCores,
dfTdist,
adaptive,
additionalPars,
dataVar,
latentIsDependent
)
}
m <- timeIndex
# save the weights of beta and latent states
wtsMatrix <- matrix(0, ncol = 2, nrow = nSteps*timeIndex)
iNode = 1
nIter <- nSteps*timeIndex
resize(mvEWSamples, nIter)
resize(mvWSamples, nIter)
essVals <- 0
pp <- 0
essVals <- essVals + impSampINLAstepFnx[[iNode]]$run(meanBeta = muStep, sigmaBeta = sigmaStep,  meanDisc = meanEcoParsStep, prevSamp = pp)
load("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/dataSimulated.RData")
load("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/dataSimulated.RData")
library(nimbIMC)
load("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/dataSimulated.RData")
library(AHMbook)
RNGversion("3.5.3")
library(INLA)
library(inlabru)
library(sp)
library(sf)
#library(rgeos)
library(INLA)
library(dplyr)
library(raster)
library(pbapply)
library(reshape)
library(tiff)
library(ggplot2)
library(gridExtra)
library(readr)
#library(terra)
library(tidyr)
library(stringr)
data("BerneseOberland")
library(nimble)
library(nimbIMC)
load("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/dataSimulated.RData")
N <- dataSimulated$nsurveys
indxOfSitesObs <- which(complete.cases(dataSimulated$yobs) == TRUE)
dataForModel <- data.frame(Longitude = dataSimulated$xcoord,
Latitude = dataSimulated$ycoord,
elevationS = dataSimulated$elevationS,
obsY = dataSimulated$yobs[,1],
i_year = as.integer(factor(rep(1, each = length(dataSimulated$xcoord))) ))%>%
as.matrix()
x <- cbind(as.matrix(dataForModel),
rep(standardize(c(dataSimulated$forest)), 1),
c(dataSimulated$wind[,1]))%>%
as.matrix()
x[ ,1] <- x[ ,1]/1000
x[ ,2] <- x[ ,2]/1000
x <- cbind(x, x[ ,3]^2)#coordsData$elevationS^2
#y = zst
inlabruModelFit <- function(x, #matrix
y, #matrix
beta, #parameters fitted from elsewhere, and should be a vector
extraVars,
fixedVals,
family){
# Simulate data
coordsData <- x%>%
as.data.frame()
#convert y to vector
y <- c(extraVars)
#p <- plogis(beta[1] + beta[2]* x[,5] + beta[3]* x[,6])
#p = c(beta)
#coordsData <- cbind(coordsData, p)
colnames(coordsData) <- c("Longitude","Latitude","elevationS", "obsY","i_year" , "forest", "wind" )
# covariate
coordsDataNew <- sf::st_as_sf(coordsData,
coords = c("Longitude",
"Latitude"))
elev.spix <- SpatialPixelsDataFrame(point =  st_coordinates(coordsDataNew),
data = data.frame(elev = (coordsDataNew$elevationS)))
elevsq.spix <- SpatialPixelsDataFrame(point =  st_coordinates(coordsDataNew),
data = data.frame(elev = ((coordsDataNew$elevationS)^2)))
# now let's get the interested covariates
coordsDataNewSubset <- sf::st_as_sf(coordsData[!is.na(coordsData$obsY),],
coords = c("Longitude",
"Latitude"))
max.edge = diff(range(sf::st_coordinates(coordsDataNewSubset)[,1]))/(3)
bound.outer = diff(range(sf::st_coordinates(coordsDataNewSubset)[,1]))/2
mesh1 = inla.mesh.2d(loc = st_coordinates(coordsDataNewSubset),
max.edge = c(max.edge,10* max.edge),
offset = c(max.edge, bound.outer))
#SPDE with exponential correlation function
spde = inla.spde2.matern(mesh = mesh1,
alpha = 1.5)
cmp <- as.formula("obsY~ - 1  + beta0(1) + site(main= i_year, model = 'iid', n = N) + w2(main = coordinates, model = spde)+ elev(main = elev.spix, model = 'linear')+ elevsq(main = elevsq.spix, model = 'linear')")
coordsDataNew1 <- as.data.frame(coordsData[!is.na(coordsData$obsY),])
coordsDataNew1 <- sp::SpatialPointsDataFrame(coords = coordsDataNew1[, c("Longitude", "Latitude")],
data = coordsDataNew1)
coordsDataNew1$obsY <- y
#coordsDataNew1$offsetIntercept <- beta[1]
lik1 <- inlabru::like(family,
formula = as.formula(paste0("obsY ~ beta0 + site +w2 + elev+ elevsq")),
#formula = as.formula(paste0("obsY ~ functionConstants(p, beta0, elev, elevsq, site, w2)")),
# formula = as.formula(paste0("obsY ~   beta0, elev, elevsq, site, w2)")),
data = coordsDataNew1,
Ntrials = 1,
domain = list(coordinates = mesh1)
)
errorIndicated <-  inherits(try(m_bru <- inlabru::bru(cmp,
lik1,
options =
list(
bru_verbose = TRUE,
bru_max_iter=1,
control.fixed = list(expand.factor.strategy = "inla",
mean = 0,
prec.intercept = 0.1,
prec = 1 / (10 * 10)
),
control.family = list(link = "logit"),
control.inla = list(int.strategy = "eb",
cmin = 0),#, strategy = "gaussian"),
control.compute=list(return.marginals.predictor=TRUE)
)
),
silent = TRUE),
"try-error"
)
#m_bru <- bru_rerun(m_bru)
#indx <- mesh1$idx$loc
# ret <- matrix(m_bru$summary.fitted.values[indx,"mean"], nrow = length(coordsData$Longitude)/N, ncol = N, byrow = FALSE)
if(errorIndicated){
ret1 <- data.frame(mld = -Inf,
NA,
NA,
NA,
NA,
NA,
NA,
# rho,
row.names = NULL)
colnames(ret1) <- c("mld", fixedVals, "siteSD", "theta1")
retFixedVals <- rep(1, nrow(coordsData))
ret1 <- cbind(ret1, retFixedVals)
}else{
samples <- inla.posterior.sample(1, m_bru)
fittedValues = c(m_bru$mlik[1,1])
fitted_values <- samples[[1]]$latent[grepl("APredictor",rownames(samples[[1]]$latent) ),1]
# fittedVals <- matrix(fitted_values,
#                      nrow = length(coordsData$Longitude)/N,
#                      ncol = N,
#                      byrow = FALSE)
fittedVals <- plogis(fitted_values)
intercept = samples[[1]]$latent[grepl("beta0:1",rownames(samples[[1]]$latent) ),1]
elev = samples[[1]]$latent[grepl("elev:1",rownames(samples[[1]]$latent) ),1]
elevsq = samples[[1]]$latent[grepl("elevsq:1",rownames(samples[[1]]$latent) ),1]
siteSD <-  samples[[1]]$hyperpar[1]
sigma <-  exp(samples[[1]]$hyperpar[2])
theta1 <- exp(samples[[1]]$hyperpar[3])
ret1 <- cbind(fittedValues, intercept, elev, elevsq,  sigma, theta1, siteSD)
#theta1 is sigma
colnames(ret1) <- c("mld", fixedVals, "siteSD")
}
#ret <- as.matrix(ret)
return(ret1)
}
fit.inlaPar <- function(x ,
y ,
betaMatrix,
extraVarsMatrix,
fixedVals,
family,
nCores){
runFnx <- function(i,
x,
y,
betaMatrix,
extraVarsMatrix,
fixedVals,
family){
res <- inlabruModelFit(x=x,
y=y,
beta = betaMatrix[i, ],
extraVars = extraVarsMatrix[i, ],
fixedVals = fixedVals,
family=family)
return(res)
}
m <- nrow(betaMatrix)
allResults <- parallel::mclapply(1:m,
runFnx,
x,
y,
betaMatrix,
extraVarsMatrix,
fixedVals,
family,
mc.cores = nCores)
ret <- do.call("rbind", allResults)
return(ret)
}
# Set up the R function for use in INLA
nimbleINLA <- nimble::nimbleRcall(
prototype = function(
x=double(2), #x is a matrix
y=integer(2), #y is a matrix
beta=double(2), # beta is a matrix
extraVarsMatrix = double(2),
fixedVals = character(1, default = c("intercept", "beta1", "beta2", "sigma","theta1")),
#interInModel = double(0, default = 1),
family = character(0, default = "binomial"),
nCores = integer(0, default = 1)
) {},
returnType = double(2), # outcome is a vector
Rfun = 'fit.inlaPar'
)
zst <- apply(dataSimulated$y[indxOfSitesObs,], 1, function(t){
r <-sum(t)
rt <- as.numeric(r>0)
#rt <- ifelse(rt==0, NA, rt)
return(rt)
})
#text if it works
inlabruModelFit(x, y = x, beta = c(2.2,2), extraVars = zst, fixedVals = c("beta0", "beta1", "beta2", "sigma","theta1"), family = "binomial")
# NIMBLE code
code <-nimbleCode({
# Specify priors
alpha0 ~ dnorm(0, 0.1)
beta0 ~ dnorm(0, 0.1)
for(v in 1:2){
alpha[v] ~ dnorm(0, 0.1)
beta[v] ~ dnorm(0, 0.1)
}
for(site.tag in 1:nsites){
for(visit.tag in 1:nvisits){
logit(p[site.tag, visit.tag]) <- alpha0 + alpha[1]*forest[site.tag] + alpha[2]*wind[site.tag, visit.tag]
}
}
###### Occupancy model
for(site.tag in 1:nsites){
logit(psi[site.tag]) <- beta0 + beta[1]*elev[site.tag] + beta[2]*elevsq[site.tag] #+ eta[site.tag]
}
for(site.tag in 1:nsites){
z[site.tag] ~ dbin(size = 1, prob = psi[site.tag])
}
#eta[1:nsites] ~ dcar_normal(adj[1:16], weights[1:16], num[1:50], tau = sigma)
# Observation model
for(site.tag in 1:nsites){
for(visit.tag in 1:nvisits){
y[site.tag, visit.tag] ~ dbin(size = 1, prob = z[site.tag]*p[site.tag, visit.tag])
}
}
#
sigma ~ dgamma(1, 0.0001)
theta1 ~ dunif(-1000, 1000)
#derived quantity
psi.fs <- sum(z[1:nsites])/nsites
})
## Parameterising the nimble model
library(spdep)
coordgrid <- cbind(dataSimulated$xcoord[indxOfSitesObs], dataSimulated$ycoord[indxOfSitesObs])
neigh <- dnearneigh(coordgrid,
d1 = 0,
d2 = sqrt(2)*1000 + 1)
winnb <- nb2WB(neigh)
str(winnb)
zst <- apply(dataSimulated$y[indxOfSitesObs,], 1, function(t){
r <-sum(t)
rt <- as.numeric(r>0)
rt <- ifelse(rt==0, NA, rt)
return(rt)
})
#Data
inla_data <- list(y = dataSimulated$y[indxOfSitesObs,],
forest = standardize(dataSimulated$forest[indxOfSitesObs]),
wind = dataSimulated$wind[indxOfSitesObs,],
elev = dataSimulated$elevationS[indxOfSitesObs],
elevsq = (dataSimulated$elevationS[indxOfSitesObs])^2,
adj = winnb$adj,
weights = winnb$weights,
num = winnb$num,
z = zst)
#Constants
const <- list(N = dataSimulated$nsurveys,
nvisits = dataSimulated$nsurveys,
nsites = length(dataSimulated$xcoord[indxOfSitesObs])
)
#zst <- apply(inla_data$y, 1, max)
#zst[is.na(zst)] <- 1
# Initial values
idm_inits <- function(){list(p = matrix(runif(const$N * const$nsites, 0, 1), nrow = const$nsites, ncol= const$N),
alpha = c(-0.2, 0.2),
alpha0 = -0.405,
beta = c(1, -1),
beta0 = 1,
sigma = 1,
eta = rep(0, const$nsites),
psi = runif(const$nsites, 0, 1)
)
}
initsList <- idm_inits()
occSpatialModel <- INLAWiNimDataGeneratingTargetDivide(data = c("y"),
covariate = x,
code = code,
family = "binomial",
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
nimbleINLA = nimbleINLA,
inlaMCMC = "importanceSampling",
samplerControl = list( scale = sqrt(10),
adaptive = TRUE,
sliceMaxSteps = 30,
extraVars = c("z"),
initMean = rnorm(3,0,1),
initCov= 2*diag(3),
initEcoPars = 0.5,
proposal = "normal",
latentIsDependent = FALSE,
spatioTemporal = TRUE,
nCores = 1),#if nCores>1, we cannot run the code o windows
parametersToMonitor = list(mcmc = c("alpha0","alpha",  "z"),
mcmcINLA = c("beta0", "sigma", "theta1"),
inla = c("beta0", "beta[1]", "beta[2]",  "sigma", "theta1"),
additionalPars = c("psi.fs")),
mcmcConfiguration = list(n.chains = 4,
n.iterations = 200,
n.burnin = 50,
n.thin = 1,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE)
)
