mc.cores = nCores)
ret <- do.call("rbind", allResults)
return(ret)
}
# Set up the R function for use in INLA
nimbleINLA <- nimble::nimbleRcall(
prototype = function(
x=double(2), #x is a matrix
y=double(2), #y is a matrix
beta=double(2), # beta is a matrix
extraVars = double(2), #extraVars is a vector
fixedVals = character(1, default = c("intercept", "beta1", "beta2", "beta3")),
#interInModel = double(0, default = 1),
family = character(0, default = "binomial"),
nCores = integer(0, default = 1)
) {},
returnType = double(2), # outcome is a vector
Rfun = 'fit.inlaPar'
)
code <- nimbleCode({
for(i in 1:nsites){
log(lambda[i]) <- beta[1] + beta[2]*x[i,1] + beta[3]*x[i,2] + beta[4]*x[i,3]
}
#lambda[1:N] <- nimbleINLA(x[1:N, 1:9], Nobs[1:N])
for(i in 1:nsites){
#N[i] ~ T(dpois(lambda[i]), Nst[i], 50)
N[i] ~ dpois(lambda[i])
}
for(i in 1:nsites){
for(j in 1:nvisits){
logit(p.tag[i,j]) <- alpha[1] + alpha[2]*x[i, 3 + j] + alpha[3]*x[i, 6 + j] + alpha[4]*pow(x[i, 6 + j],2)
}
}
# for(i in 1:nsites){
#  for(j in 1:nvisits){
#     pNb[i] <- rho/ (rho + (lambda[i]))
#  }
# }
# rho ~ dunif(0.0001, 10)
for(i in 1:nsites){
for(j in 1:nvisits){
y[i,j] ~ dbin(prob = p.tag[i,j], size = N[i])
}
}
#Prior distributions
for(i in 1:4){
alpha[i] ~ dnorm(0, 0.001)
}
for(i in 1:4){
beta[i] ~ dnorm(0, 1)
}
# Derived quantity
Ntotal <- sum(N[1:nsites])
})
Nst <- as.numeric(apply(mallard.inla.df[,1:3], 1, max, simplify = TRUE))
inla_data <- list(y=mallard.inla.df[,1:3],
x = x,
y_obs=mallard.inla.df[,1:3])
#Constants
const <- list(nsites = nrow(inla_data$y),
nvisits = ncol(inla_data$y),
Nst = Nst)
# Initial values
idm_inits <- function(){list(beta = rep(1, 4),
alpha = rep(0, 4),
rho = 0.8,
N = rep(30, const$nsites)
)
}
initsList <- idm_inits()
bayesianNMix <- INLAWiNimDataGeneratingTargetDivide(data = c("y"),
covariate = as.matrix(x),
code = code,
family = "binomial",
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
nimbleINLA = nimbleINLA,
inlaMCMC = "importanceSampling",
parametersToMonitor = list(inla = c("alpha"),
mcmc = c("beta", "N"),
mcmcINLA = c("alpha"),
additionalPars = c("Ntotal")),
# inlaMCsampler = samplers[i],
samplerControl = list(#interInModel = 0,
#            mu = c(rep(mean(inla_data$x[,3], na.rm = T),9)),
scale = sqrt(10),
adaptive = TRUE,
sliceMaxSteps = 30,
extraVars = c("N"),
initMean = rnorm(4,0,1),
initCov= 1*diag(4),
proposal = "normal",
nCores = 1),
mcmcConfiguration = list(n.chains = 5,
n.iterations = 2000,
n.burnin = 100,
n.thin = 3,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE)
)
bayesianNMix <- INLAWiNimDataGeneratingTargetDivide(data = c("y"),
covariate = as.matrix(x),
code = code,
family = "binomial",
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
nimbleINLA = nimbleINLA,
inlaMCMC = "importanceSampling",
parametersToMonitor = list(inla = c("alpha"),
mcmc = c("beta", "N"),
mcmcINLA = c("alpha"),
additionalPars = c("Ntotal")),
# inlaMCsampler = samplers[i],
samplerControl = list(#interInModel = 0,
#            mu = c(rep(mean(inla_data$x[,3], na.rm = T),9)),
scale = sqrt(10),
adaptive = TRUE,
sliceMaxSteps = 30,
extraVars = c("N"),
initMean = rnorm(4,0,1),
initCov= 1*diag(4),
proposal = "normal",
nCores = 1),
mcmcConfiguration = list(n.chains = 3,
n.iterations = 100,
n.burnin = 10,
n.thin = 3,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE)
)
bayesianNMix$isINLA$mcmc.out$samples$
bayesianNMix$isINLA$mcmc.out$samples
tail(bayesianNMix$isINLA$mcmc.out$samples[[1]])
code <- nimbleCode({
for(i in 1:nsites){
log(lambda[i]) <- beta[1] + beta[2]*x[i,1] + beta[3]*x[i,2] + beta[4]*x[i,3]
}
#lambda[1:N] <- nimbleINLA(x[1:N, 1:9], Nobs[1:N])
for(i in 1:nsites){
N[i] ~ T(dpois(lambda[i]), Nst[i], 15)
#N[i] ~ dpois(lambda[i])
}
for(i in 1:nsites){
for(j in 1:nvisits){
logit(p.tag[i,j]) <- alpha[1] + alpha[2]*x[i, 3 + j] + alpha[3]*x[i, 6 + j] + alpha[4]*pow(x[i, 6 + j],2)
}
}
# for(i in 1:nsites){
#  for(j in 1:nvisits){
#     pNb[i] <- rho/ (rho + (lambda[i]))
#  }
# }
# rho ~ dunif(0.0001, 10)
for(i in 1:nsites){
for(j in 1:nvisits){
y[i,j] ~ dbin(prob = p.tag[i,j], size = N[i])
}
}
#Prior distributions
for(i in 1:4){
alpha[i] ~ dnorm(0, 0.001)
}
for(i in 1:4){
beta[i] ~ dnorm(0, 1)
}
# Derived quantity
Ntotal <- sum(N[1:nsites])
})
Nst <- as.numeric(apply(mallard.inla.df[,1:3], 1, max, simplify = TRUE))
inla_data <- list(y=mallard.inla.df[,1:3],
x = x,
y_obs=mallard.inla.df[,1:3])
#Constants
const <- list(nsites = nrow(inla_data$y),
nvisits = ncol(inla_data$y),
Nst = Nst)
# Initial values
idm_inits <- function(){list(beta = rep(1, 4),
alpha = rep(0, 4),
rho = 0.8,
N = rep(30, const$nsites)
)
}
initsList <- idm_inits()
bayesianNMix <- INLAWiNimDataGeneratingTargetDivide(data = c("y"),
covariate = as.matrix(x),
code = code,
family = "binomial",
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
nimbleINLA = nimbleINLA,
inlaMCMC = "importanceSampling",
parametersToMonitor = list(inla = c("alpha"),
mcmc = c("beta", "N"),
mcmcINLA = c("alpha"),
additionalPars = c("Ntotal")),
# inlaMCsampler = samplers[i],
samplerControl = list(#interInModel = 0,
#            mu = c(rep(mean(inla_data$x[,3], na.rm = T),9)),
scale = sqrt(10),
adaptive = TRUE,
sliceMaxSteps = 30,
extraVars = c("N"),
initMean = rnorm(4,0,1),
initCov= 1*diag(4),
proposal = "normal",
nCores = 1),
mcmcConfiguration = list(n.chains = 3,
n.iterations = 100,
n.burnin = 10,
n.thin = 3,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE)
)
load("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/dataSimulated.RData")
source("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/isINLA/isINLA.R", echo=TRUE)
source("C:/Users/kwaku.adjei/Dropbox/PhD Docs/Data for PHD/inlaWithNimble/codeForPaper/spatialOccupancyModel/isINLA/isINLA.R", echo=TRUE)
occSpatialModel$isINLA$mcmc.out$summary
occSpatialModel <- INLAWiNimDataGeneratingTargetDivide(data = c("y"),
covariate = x,
code = code,
family = "binomial",
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
nimbleINLA = nimbleINLA,
inlaMCMC = "importanceSampling",
samplerControl = list( scale = sqrt(10),
adaptive = TRUE,
sliceMaxSteps = 30,
extraVars = c("z"),
initMean = rnorm(3,0,1),
initCov= 1*diag(3),
proposal = "normal",
latentIsDependent = FALSE,
nCores = 1),
parametersToMonitor = list(mcmc = c("alpha0","alpha", "z"),
mcmcINLA = c("beta0", "beta[1]","beta[2]", "sigma"),
inla = c("beta0", "beta[1]","beta[2]", "sigma"),
additionalPars = c("psi.fs")),
mcmcConfiguration = list(n.chains = 10,
n.iterations = 20,#500,
n.burnin = 5,#00,
n.thin = 2,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE)
)
library(unmarked)
data("mallard")
library(nimbIMC)
length <- mallard.site[ , "length"]
elev <- mallard.site[, "elev"]
forest <- mallard.site[, "forest"]
mean.ivel <- mallard.obs$ivel
mean.date <- mallard.obs$date
# unmarked
mallard.umf <- unmarkedFramePCount(y = mallard.y,
siteCovs = mallard.site,
obsCovs = mallard.obs)
out.unmk.2 <- pcount(~ ivel + date + I(date^2) ~ length + elev + forest,
mixture = "P",
data = mallard.umf)
summary(out.unmk.2)
mallard.inla.df <- data.frame(y1 = mallard.y[ , "y.1"],
y2 = mallard.y[ , "y.2"],
y3 = mallard.y[ , "y.3"],
length = length,
elev = elev,
forest = forest,
mean.ivel,
mean.date)
#na.omit(mallard.inla.df[ , -c(1,2,3)])
mallard.inla.df <- mallard.inla.df[-25,]
mallard.inla.df <- mallard.inla.df[complete.cases(mallard.inla.df),]%>%
dplyr::mutate_at(c("length", "elev", "forest", "ivel.1", "ivel.2", "ivel.3", "date.1", "date.2", "date.3"), funs(sca = scale(.)))
mallard.inla.df <- mallard.inla.df[, c(1:3, 13:21) ]
#column means should be close to 0
colMeans(mallard.inla.df)
fixedVals = c("intercept", "beta1", "beta2", "beta3")
x <- mallard.inla.df[ , -c(1,2,3)]
y <- mallard.inla.df[ , c(1,2,3)]
fit.inla <- function(x ,
y ,
beta,
extraVars,
fixedVals,
family
){
#convert y to vector
n <- nrow(y)
y <- c(unlist(y))
ivel <- c(unlist(x[,4:6]))
date <- c(unlist(x[,7:9]))
extraVars <- as.numeric(extraVars)
date.sq <- date^2
site <- c(rep(1, n), rep(2,n), rep(3,n))
data <- data.frame(ivel = ivel,
date = date,
date.sq = date.sq,
site = site,
y = y,
nTrials = rep(extraVars, 3))
#p <- plogis(beta[1] + beta[2]*ivel + beta[3]* date + beta[4]* (date)^2)
#list(y=y, x=x)
#data$oset = data$x %*% beta
errorIndicated <-  inherits(try(res <- INLA::inla(y ~ 1 + ivel + date + date.sq + f(site, model = "iid"),
data = data,
family = "binomial",
Ntrials =  nTrials,
control.family= list(link = 'logit'),
control.compute = list(config = TRUE),
control.predictor = list(compute=TRUE,
link = 1)),
silent = TRUE),
"try-error"
)
#generate samples
# samples <- inla.posterior.sample(1, res)
# fitted_values <- samples[[1]]$latent[grepl("Predictor",rownames(samples[[1]]$latent) ),1]
# intercept = samples[[1]]$latent[grepl("(Intercept)",rownames(samples[[1]]$latent) ),1]
# length = samples[[1]]$latent[grepl("length",rownames(samples[[1]]$latent) ),1]
# elev = samples[[1]]$latent[grepl("elev",rownames(samples[[1]]$latent) ),1]
# forest = samples[[1]]$latent[grepl("forest",rownames(samples[[1]]$latent) ),1]
if(errorIndicated){
ret <- data.frame(mld = -Inf,
NA,
NA,
NA,
NA,
# rho,
row.names = NULL)
}else{
fitted_values = c(res$mlik[1,1])
samples <- inla.posterior.sample(1, res)
#fitted_values <- plogis(samples[[1]]$latent[grepl("Predictor",rownames(samples[[1]]$latent) ),1])
intercept = samples[[1]]$latent[grepl("(Intercept)",rownames(samples[[1]]$latent) ),1]
beta1 = samples[[1]]$latent[grepl("ivel",rownames(samples[[1]]$latent) ),1]
beta2 = samples[[1]]$latent[grepl("date",rownames(samples[[1]]$latent) ),1][1]
beta3 = samples[[1]]$latent[grepl("date.sq",rownames(samples[[1]]$latent) ),1]
#intercept = INLA::inla.emarginal(function(x) x,res$marginals.fixed[[1]])
#beta1 = INLA::inla.emarginal(function(x) x,res$marginals.fixed[[2]])
#beta2 = INLA::inla.emarginal(function(x) x,res$marginals.fixed[[3]])
#beta3 = INLA::inla.emarginal(function(x) x,res$marginals.fixed[[4]])
# rho = INLA::inla.emarginal(function(x) x,res$marginals.hyperpar[[1]])
#precision = INLA::inla.emarginal(function(x) x,res$marginals.hyper[[1]])
ret <- data.frame(mld = fitted_values,
intercept,
beta1,
beta2,
beta3,
# rho,
row.names = NULL)
}
# colnames(ret) <- c("mld", fixedVals)
ret <- as.matrix(ret)
#ret <- c(ret)
return(ret)
}
fit.inlaPar <- function(x ,
y ,
betaMatrix,
extraVars,
fixedVals,
family,
nCores){
runFnx <- function(i,
x,
y,
betaMatrix,
extraVars,
fixedVals,
family){
res <- fit.inla(x=x,
y=y,
beta = betaMatrix[i, ],
extraVars[i, ],
fixedVals = fixedVals,
family=family)
return(res)
}
m <- nrow(betaMatrix)
allResults <- parallel::mclapply(1:m,
runFnx,
x,
y,
betaMatrix,
extraVars,
fixedVals,
family,
mc.cores = nCores)
ret <- do.call("rbind", allResults)
return(ret)
}
# Set up the R function for use in INLA
nimbleINLA <- nimble::nimbleRcall(
prototype = function(
x=double(2), #x is a matrix
y=double(2), #y is a matrix
beta=double(2), # beta is a matrix
extraVars = double(2), #extraVars is a vector
fixedVals = character(1, default = c("intercept", "beta1", "beta2", "beta3")),
#interInModel = double(0, default = 1),
family = character(0, default = "binomial"),
nCores = integer(0, default = 1)
) {},
returnType = double(2), # outcome is a vector
Rfun = 'fit.inlaPar'
)
code <- nimbleCode({
for(i in 1:nsites){
log(lambda[i]) <- beta[1] + beta[2]*x[i,1] + beta[3]*x[i,2] + beta[4]*x[i,3]
}
#lambda[1:N] <- nimbleINLA(x[1:N, 1:9], Nobs[1:N])
for(i in 1:nsites){
N[i] ~ T(dpois(lambda[i]), Nst[i], 112)
#N[i] ~ dpois(lambda[i])
}
for(i in 1:nsites){
for(j in 1:nvisits){
logit(p.tag[i,j]) <- alpha[1] + alpha[2]*x[i, 3 + j] + alpha[3]*x[i, 6 + j] + alpha[4]*pow(x[i, 6 + j],2)
}
}
# for(i in 1:nsites){
#  for(j in 1:nvisits){
#     pNb[i] <- rho/ (rho + (lambda[i]))
#  }
# }
# rho ~ dunif(0.0001, 10)
for(i in 1:nsites){
for(j in 1:nvisits){
y[i,j] ~ dbin(prob = p.tag[i,j], size = N[i])
}
}
#Prior distributions
for(i in 1:4){
alpha[i] ~ dnorm(0, 0.001)
}
for(i in 1:4){
beta[i] ~ dnorm(0, 0.00001)
}
# Derived quantity
Ntotal <- sum(N[1:nsites])
})
Nst <- as.numeric(apply(mallard.inla.df[,1:3], 1, max, simplify = TRUE))
inla_data <- list(y=mallard.inla.df[,1:3],
x = x,
y_obs=mallard.inla.df[,1:3])
#Constants
const <- list(nsites = nrow(inla_data$y),
nvisits = ncol(inla_data$y),
Nst = Nst)
# Initial values
idm_inits <- function(){list(beta = rep(0.1, 4),
alpha = rep(0, 4),
rho = 0.8,
N = rep(10, const$nsites)
)
}
initsList <- idm_inits()
data = c("y")
covariate = as.matrix(x)
initsList <- idm_inits()
bayesianNMix <- INLAWiNimDataGeneratingTargetDivide(data = c("y"),
covariate = as.matrix(x),
code = code,
family = "binomial",
modelData = inla_data,
modelConstants = const,
modelInits = idm_inits,
nimbleINLA = nimbleINLA,
inlaMCMC = "importanceSampling",
parametersToMonitor = list(inla = c("alpha"),
mcmc = c("beta", "N"),
mcmcINLA = c("alpha"),
additionalPars = c("Ntotal")),
# inlaMCsampler = samplers[i],
samplerControl = list(#interInModel = 0,
#            mu = c(rep(mean(inla_data$x[,3], na.rm = T),9)),
scale = sqrt(10),
adaptive = TRUE,
sliceMaxSteps = 30,
dfTdist = 1,
extraVars = c("N"),
initMean = rep(0.01, 4),
initCov= 1*diag(4),
proposal = "studentT",
nCores = 1),
mcmcConfiguration = list(n.chains = 3,
n.iterations = 200,
n.burnin = 10,
n.thin = 3,
setSeed = TRUE,
samples=TRUE,
samplesAsCodaMCMC = TRUE,
summary = TRUE,
WAIC = FALSE)
)
